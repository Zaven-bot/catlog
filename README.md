# ğŸ¾ CatLog â€“ Anime Tracking with Data Engineering Pipeline

CatLog is a full-stack anime tracking application that combines modern web development with a robust data engineering pipeline. Built as a portfolio project showcasing both frontend development skills and data engineering capabilities using real anime data from the Jikan API.

## ğŸ¯ Purpose

CatLog demonstrates two key technical areas:
- **Frontend Development**: React/Next.js application for anime discovery and tracking
- **Data Engineering**: Production-ready ETL pipeline for processing anime data at scale

This project showcases practical skills in full-stack development, data pipeline architecture, and modern DevOps practices.

---

## ğŸ› ï¸ Tech Stack

| Layer              | Technology                                    |
|--------------------|-----------------------------------------------|
| **Frontend**       | Next.js, TypeScript, TailwindCSS             |
| **Backend API**    | Node.js, Express, RESTful APIs               |
| **Database**       | PostgreSQL + Prisma ORM                      |
| **Authentication** | JWT (stateless authentication)               |
| **Data Pipeline**  | Python ETL with Jikan API integration        |
| **External APIs**  | Jikan (MyAnimeList data)                     |
| **Testing**        | Jest (unit), Pytest (ETL)                    |
| **Deployment**     | Vercel (frontend), Render (backend)          |

---

## ğŸ¯ Current Features

### ğŸ± Virtual Cat Companion
- Interactive cat that reacts to user activity
- Different moods and animations based on anime tracking behavior
- Quick action suggestions based on cat's current mood

### ğŸ“º Anime Discovery & Tracking
- Browse trending, seasonal, and all-time favorite anime
- Detailed anime information pages with ratings, genres, and synopsis
- Personal anime list management with status tracking:
  - Currently Watching
  - Completed
  - Plan to Watch
  - On Hold
  - Dropped
- Personal ratings and notes for each anime

### ğŸ” Search & Discovery
- Real-time anime search using Jikan API
- Advanced filtering and pagination
- Recently searched anime tracking

### ğŸ“Š Statistics Dashboard
- Personal anime statistics and viewing habits
- Interactive charts showing:
  - Status breakdown (watching, completed, etc.)
  - Top genres from your list
  - Personal rating distribution
  - Viewing activity over time

### ğŸ” User Management
- JWT-based authentication system
- User registration and login
- Protected routes and secure API access
- Personal profile management

---

## ğŸ—ï¸ Data Engineering Pipeline

### ETL Pipeline (IMPLEMENTED)
A production-ready ETL pipeline that processes anime data from the Jikan API:

**Features:**
- **Extract**: Pulls trending and seasonal anime data from Jikan API with rate limiting
- **Transform**: Converts raw JSON data into structured, validated format
- **Load**: Stores both raw and processed data in PostgreSQL
- **Logging**: Comprehensive ETL run tracking and error handling
- **CLI Interface**: Easy-to-use command-line tools
- **Unit Tests**: Full test coverage for all ETL functions

**Database Schema:**
- `RawAnimeData`: Stores complete JSON responses from Jikan API
- `ProcessedAnime`: Structured, transformed anime data ready for analysis
- `EtlLogs`: Comprehensive logging of all ETL pipeline runs

**Usage:**
```bash
# Run ETL pipeline
cd etl
python pipeline.py run

# Extract seasonal anime
python pipeline.py run --source seasonal --year 2024 --season winter

# View recent ETL logs
python pipeline.py logs

# Test database connection
python pipeline.py test-connection
```

**Monitoring & Error Handling:**
- Unique run IDs for tracking
- Start/end timestamps and duration tracking
- Success/failure status logging
- Row count processing metrics
- Detailed error messages and stack traces
- Rate limiting and retry logic for API calls

---

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+
- Python 3.9+
- PostgreSQL database

### 1. Clone and Install
```bash
git clone <repository-url>
cd catlog

# Install backend dependencies
cd backend
npm install

# Install frontend dependencies
cd ../frontend
npm install

# Install ETL dependencies
cd ../etl
pip install -r requirements.txt
```

### 2. Database Setup
```bash
# Set up environment variables
cp backend/.env.example backend/.env
# Edit backend/.env with your database credentials

# Run database migrations
cd backend
npx prisma migrate dev
```

### 3. ETL Pipeline Setup
```bash
# Configure ETL environment
cd etl
cp .env.example .env
# Edit .env with your database credentials

# Test ETL connection
python pipeline.py test-connection

# Run initial data load
python pipeline.py run --max-pages 5
```

### 4. Start Development Servers
```bash
# Start backend (terminal 1)
cd backend
npm run dev

# Start frontend (terminal 2)
cd frontend
npm run dev
```

Visit `http://localhost:3000` to see the application.

---

## ğŸ“ Project Structure

```
catlog/
â”œâ”€â”€ README.md
â”œâ”€â”€ backend/                 # Node.js API server
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ controllers/     # API route handlers
â”‚   â”‚   â”œâ”€â”€ middleware/      # Auth, CORS, error handling
â”‚   â”‚   â”œâ”€â”€ routes/         # API route definitions
â”‚   â”‚   â”œâ”€â”€ services/       # External API integrations
â”‚   â”‚   â””â”€â”€ utils/          # JWT, validation utilities
â”‚   â””â”€â”€ prisma/             # Database schema & migrations
â”œâ”€â”€ frontend/               # Next.js React application
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app/            # Next.js 13+ app router pages
â”‚       â”œâ”€â”€ components/     # Reusable React components
â”‚       â”œâ”€â”€ hooks/          # Custom React hooks
â”‚       â””â”€â”€ stores/         # State management
â”œâ”€â”€ etl/                    # Python ETL pipeline
â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â”œâ”€â”€ database.py         # Database operations
â”‚   â”œâ”€â”€ extractor.py        # Jikan API data extraction
â”‚   â”œâ”€â”€ transformer.py      # Data transformation
â”‚   â”œâ”€â”€ pipeline.py         # Main ETL orchestrator & CLI
â”‚   â””â”€â”€ tests/              # ETL unit tests
â””â”€â”€ shared/                 # Shared TypeScript types
```

---

## ğŸ§ª Testing

### Backend API Tests
```bash
cd backend
npm test
```

### ETL Pipeline Tests
```bash
cd etl
python -m pytest tests/ -v
```

---

## ğŸ“Š Data Flow Architecture

```
Jikan API â†’ ETL Pipeline â†’ PostgreSQL â†’ Backend API â†’ Frontend
    â†“            â†“             â†“           â†“           â†“
Raw JSON â†’ Transformation â†’ Structured â†’ REST API â†’ React UI
   +              +            Data        +          +
Validation â†’ Error Handling â†’ Indexing â†’ Caching â†’ State Mgmt
```

**ETL Pipeline Flow:**
1. **Extract**: Fetch anime data from Jikan API with rate limiting
2. **Transform**: Clean, validate, and structure raw JSON data
3. **Load**: Store in PostgreSQL with comprehensive logging
4. **Monitor**: Track pipeline runs, errors, and performance metrics

---

## ğŸ¯ Development Roadmap

### Completed âœ…
- Core anime tracking functionality
- User authentication and management
- Real-time anime search and discovery
- Personal statistics dashboard
- Virtual cat companion with mood system
- Production-ready ETL pipeline
- Comprehensive error handling and logging
- Unit test coverage for ETL functions

### In Progress / Future Enhancements
- Cloud data warehouse integration (BigQuery)
- Apache Airflow orchestration
- Real-time streaming data updates
- Data quality validation with Great Expectations
- Containerization and cloud deployment
- CI/CD pipeline automation

---

## ğŸš€ Deployment

### Frontend
- Deployed on [Vercel](https://vercel.com/)
- Automatic deployments from main branch
- Environment variables configured for production API endpoints

### Backend
- Deployed on [Render](https://render.com/)
- PostgreSQL database on [Supabase](https://supabase.com/)
- JWT-based stateless authentication
- CORS configured for production frontend

### ETL Pipeline
- Can be scheduled via cron for regular data updates
- Supports both manual and automated execution
- Production-ready error handling and logging

---

## ğŸ’¡ Technical Highlights

### Data Engineering
- **ETL Architecture**: Modular, testable pipeline design
- **Error Handling**: Comprehensive logging and graceful failure recovery
- **Data Quality**: Validation and transformation with detailed audit trails
- **Scalability**: Configurable batch processing and rate limiting
- **Monitoring**: Detailed metrics and run tracking

### Full-Stack Development
- **Type Safety**: End-to-end TypeScript implementation
- **State Management**: React hooks with optimistic updates
- **API Design**: RESTful endpoints with proper error handling
- **Database Design**: Normalized schema with proper indexing
- **Authentication**: Secure JWT implementation with protected routes

### DevOps & Quality
- **Testing**: Unit tests for both backend and ETL components
- **Documentation**: Comprehensive README and inline code documentation
- **Configuration**: Environment-based configuration management
- **Logging**: Structured logging with timestamps and error tracking

---

## ğŸ“ˆ Success Metrics

- âœ… Users can register, login, and manage their anime lists
- âœ… Search returns real anime data from Jikan API
- âœ… Cat companion responds meaningfully to user activity
- âœ… Statistics show real user data trends
- âœ… ETL pipeline processes data reliably with comprehensive logging
- âœ… Application is deployed and accessible online
- âœ… Performance is smooth on mobile and desktop

**Total Development Time**: ~80 hours across frontend, backend, and data pipeline

---

## ğŸ¤ Contributing

This is a portfolio project, but feedback and suggestions are welcome! Please feel free to:
- Report bugs or issues
- Suggest new features
- Provide feedback on code quality or architecture

---

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).
